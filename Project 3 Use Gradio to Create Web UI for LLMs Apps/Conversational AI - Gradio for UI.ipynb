{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c163efb8-882a-4a30-ae78-309046874b3a",
   "metadata": {},
   "source": [
    "# Conversational AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf19ebf-f017-4b9a-9d1f-b0f75c13e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e65b2e1-b60b-43c4-8ee9-5c823f5e1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "os.environ['ANTHROPIC_API_KEY'] = \"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\"\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDAnwJN70IlLu5FcC7DZBWVXLAYgOqoDqk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ba3a53-a795-4bdc-b159-16542ef8a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22599604-14f2-43c1-a0e9-4e402407302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful AI assistant\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b4c96-ece0-4ecb-9e56-376e6186fb0f",
   "metadata": {},
   "source": [
    "# Reminder of the structure of prompt messages to OpenAI:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f7b9f-2656-4fec-b43d-9af031872d45",
   "metadata": {},
   "source": [
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    \n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a02139-0b77-46bc-840e-7549b77c1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history is a list of pairs of user message with assistant's reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c80fb-83ad-4d73-ade7-41da267dd712",
   "metadata": {},
   "source": [
    "[\n",
    "    [\"user said this\", \"assistant replied\"],\n",
    "    \n",
    "    [\"then user said this\", \"and assistant replied again],\n",
    "    ...\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a476186-d04d-4d29-9587-7a9249b49382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = prior mesage \n",
    "# message = user says "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9244c4e2-66d2-4d6e-8be2-e697decabc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio needs this format \n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    \n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec5b17-c096-4345-91dd-b0c09a3c34c0",
   "metadata": {},
   "source": [
    "# And then enter Gradio's magic!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e7bc748-e10d-4c52-aed8-b55557e82843",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales evemt.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "673f07bf-b9d7-43c8-8b4f-25f1c7a4edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "532821c6-c1fd-424e-a112-e20aa9230a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40a0de6b-0794-4f29-a060-17b7a39e94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd59624-6e73-411d-8d01-83af740851c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
